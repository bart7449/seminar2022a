# Seminar II: Deep Learning-based Natural Language Processing
Natural language processing (NLP) is a crucial part of artificial intelligence (AI), modeling how machine understand and generate human languages.  
In recent years, deep learning approaches have obtained very high performance on many NLP tasks. 
In this course, students will gain knowledge about cutting-edge neural networks for NLP.

## Course Information
- This course meets for in-class lecture Fri 15:00 - 17:00 (Seminar room No.2 at KISTI KIUM).
- In this seminar class, students are asked to review seminal papers related to NLP techniques and present them in the class.
- Two or three papers will be reviewed every week. 
- For all inquiries related to this course, please contact kyongha@kisti.re.kr

### Instructor
This seminar is supervised by Dr. Kyong-Ha Lee at <a href="https://www.ust.ac.kr/prog/major/eng/sub03_03_02/IR/view.do?majorNo=32">KISTI campus</a>. 

### Time and Location
- Fri. 15:00  ~ 17:00
- <span style="color:red">Due to the spread of COVID 19 virus, some lectures may be held online.</span> 
## Materials
- Related lecture : Stanford CS224N http://web.stanford.edu/class/cs224n/
- A curated list of resources dedicated to Natural Language Processing https://github.com/keon/awesome-nlp
- All slides for this seminar class will be available here. 
## Logistics
- All course announcements take place though this page. Please check this page frequently.
- You must submit your presentation materials to me by e-mail one day before class.
- 
### Class components and grading
- Your grade will be recorded as a success or failure 

|Event|Date| In-class Presentation| Materials and Assignments|
|---------|-------|---------------------|------------|
|Week 1|4 March 2022| Course Introduction| None|
|Week 2|11 March 2022|Word embeddings<ul><li>Word2Vec<li>GloVe|<ul><li><a href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a> (original word2vec paper)<li><a href="https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>(negative sampling paper)|
|Week 3|18 March 2022|<ul><li>Network archtecture<li>NLP from scratch|<ul><li><a href="https://cs231n.github.io/neural-networks-1/">cs231n notes on network architectures</a><li><a href="https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf">Natural Language Processing(Almost from Scratch)</a>|
|Week 4|18 March 2022|<ul><li>N-gram Language Models<li>Sequence Modeling:Recurrent and Recursive neural Nets|<ul><li>N-gram Language Models (textbook chapter)<li>The Unreasonable Effectiveness of Recurrent Neural Networks (blog post overview) <li>Sequence Modeling: Recurrent and Recursive Neural Nets (Sections 10.1 and 10.2)|  
|Week 5| | | |
